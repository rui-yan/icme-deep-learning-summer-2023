---
layout: default
---

# Workshop Description

Deep Learning is a rapidly expanding field with new applications found every day. In this workshop, we will cover the fundamentals of deep learning for the beginner. 

We will introduce the math behind training deep learning models: the back-propagation algorithm. Building conceptual understanding of the fundamentals of deep learning will be the focus of the first part of the workshop. We will then cover some of the popular architectures used in deep learning, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), LSTMs, autoencoders and GANs. 

There will be a hands-on computing tutorial using Jupyter notebooks to build a basic image classification model via transfer learning.  By the end of the workshop, participants will have a firm understanding of the basic terminology and jargon of deep learning and will be prepared to dive into the plethora of online resources and literature available for each specific application area.


## About the Instructor

![Aashwin Mishra](/assets/img/aashwin.png){:style="max-width:30%;"}

Aashwin Mishra is a Project Scientist at the Machine Learning Initiative at the National Accelerator Laboratory (SLAC). His research focuses on uncertainty quantification, probabilistic modeling, interpretability/explainability, and optimization across physics applications.

## About the Teaching Assistant

![Rui Yan](/assets/img/ruiyan.png){:style="max-width:30%;"}

Rui Yan is a Ph.D. candidate at ICME, Stanford.
Her research focuses on developing machine learning algorithms to extract meaningful representations from large-scale, high-dimensional and multi-modal data.
She has interned at Meta, Uber AI, and Microsoft Research.

# Workshop Materials

## Pre-workshop Checklist

The Zoom link to the course can be found [here](https://stanford.zoom.us/j/97867338375?pwd=VngzV2dRRExlK1Bkcnk4TzMrN1RoZz09).

The workshop assumes that you have requisite knowledge of:

a) Python programming

b) Numpy

c) basic concepts of Machine Learning (desirable)


For (a), you should have written codes in Python, and at some juncture, defined and used a class.

For (b), you should be comfortable in basic linear algebra operations in Numpy, understand broadcasting, etc.

(c) is desirable, but not required.

## Schedule

#### Session 1 (Monday, August 7 | 8:00 AM - 11:00 AM PDT)

- Review of basic ML concepts
- Overview of deep learning
- Coding a perceptron in numpy
- Understanding fully connected neural networks
- Coding fully connected neural networks in numpy
- Introduction to Torch
- Using the AD facilities in torch to train models
- Using the sub-modules in torch to define and train models

Zoom recording Day 1: [Link](https://drive.google.com/file/d/1mNy2tjWgbLwtlBXs6LCNqGNBfjU7IIXk/view?usp=sharing)

#### Session 2 (Tuesday, August 8 | 8:00 AM - 11:00 AM PDT)

- Understanding Convolutional Neural Networks
- Defining and Training CNNs in torch
- Using GPUs for training
- Data Augmentation

Zoom recording Day 2: [Link](https://stanford.zoom.us/rec/share/Am_MBUsXNUJhxPdGC0TXYEf94nWIxNGLDfQ0rDHMY5XkNr0j_oHHDytxu10C35ik.59LNlF9zFu2gXHZS?startTime=1691505782000&pwd=wIGB4YNczYrSV7kSzEt59pfXrPcvKbSP)

## Google Colab notebooks

- [Linear Regression Exercise in Numpy](https://colab.research.google.com/drive/1w0C62ikCOotfBJ5FbzQu4I3weu6viAmj?usp=sharing)
- [Solutions: Linear Regression Exercise in Numpy](https://colab.research.google.com/drive/1w0C62ikCOotfBJ5FbzQu4I3weu6viAmj?usp=sharing)
- [Shallow Neural Network in Numpy](https://colab.research.google.com/drive/1mbquyEd_N_JMh8nTupbXgId1ArVZuP3L?usp=sharing)
- [Solutions: Shallow Neural Network in Numpy](https://colab.research.google.com/drive/1mbquyEd_N_JMh8nTupbXgId1ArVZuP3L?usp=sharing)
- [Introduction to Torch](https://colab.research.google.com/drive/1b1ifUhsdo7rYeUEKBjEQkWTgWX0EgEz6?usp=sharing)
- [My First Torch Model](https://colab.research.google.com/drive/1GLihAAAmsz1Snqt2GLg55hSO0UQWBGLM?usp=sharing)
- [MNIST with an FCNN](https://colab.research.google.com/drive/1Wp2jWYnZ50VWBPCVEkPemUcF3ohrxrct?usp=sharing)
- [CIFAR10 with CNNs](https://colab.research.google.com/drive/1eZniJ3FW77cAy4U3cSieJPSq-ukMARPY?usp=sharing)
- [CIFAR10 with GPUs](https://colab.research.google.com/drive/153nTZtmHENNTx-XLWw3kl41Shd-ZvXVJ?usp=sharing)
- [Data Augmentation for Computer Vision](https://colab.research.google.com/drive/1Ug0STBPfwc0Q7YSBasliIJCC38y9pOVm?usp=sharing)

## References
- [Model interpretability: SHAP](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)
- [Model interpretability: LIME](https://arxiv.org/abs/1602.04938)
- [Explainable AI tutorial](https://explainml-tutorial.github.io/neurips20)
